Web Crawler
==================================================
This is a simple web crawler written in Python, its purpose is to
read and input url and a level of depth and then start crawling 
recursively that web and display and store the child links included.

The project code is hosted in Github under:

	https://github.com/eparrillae/eparrillae-mswl/tree/master/Development/eparrillae-crawler

The PyPi page of the project can be found here:

	http://pypi.python.org/pypi/eparrillae-crawler/1.0.

The project Documentation, Wiki and Bugtracker/Roadmap is hosted in Sidelab forge at:

	http://code.sidelab.es/projects/estherparrilla

This software is licensed under the MIT license available at:

	http://www.opensource.org/licenses/mit-license.php 

Web Crawler Requirements
==================================================
* Python 2.7 or above, this script has been tested using Python 2.7.1+ [ http://python.org/ ]
* Beautiful Soup HTML parser installed [ http://www.crummy.com/software/BeautifulSoup/ ]

How to run the script
=====================
Simply execute in the console (for example for crawling Google) in 2 depth levels: 

	$./eparrillae-crawler.py -n 2 http://www.google.com


